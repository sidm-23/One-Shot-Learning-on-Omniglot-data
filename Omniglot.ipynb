{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Omniglot.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidm-23/One-Shot-Learning-on-Omniglot-data/blob/master/Omniglot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gcI6z3TXuE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing all the required  modules\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6YLDJJfXuFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_image_data(folder):\n",
        "    \n",
        "    \"\"\"\n",
        "    Get Training and evaluaation data for images\n",
        "    It return the data in a DataFrame with multiple index\n",
        "    \"\"\"\n",
        "    \n",
        "    lang_list=[]#list of of languages\n",
        "    X={}\n",
        "    Y={}\n",
        "    for languages in os.listdir(folder):\n",
        "        if languages.startswith('.'):\n",
        "            continue#ignore all hidden files\n",
        "        else:\n",
        "            images={}\n",
        "            lang_list.append(languages)\n",
        "            chars=[]\n",
        "            for alphabets in os.listdir(folder+languages):\n",
        "                im=[]\n",
        "                chars.append(alphabets)\n",
        "                for character in os.listdir(folder+languages+\"/\"+alphabets):\n",
        "                    if(character.startswith('.')):\n",
        "                        continue\n",
        "                    else:\n",
        "                        im.append(cv2.imread(folder+languages+\"/\"+alphabets+\"/\"+character))#append image data\n",
        "                images[alphabets]=im#for each character\n",
        "                Y[languages]=chars#for each language type\n",
        "#             print(languages)\n",
        "            X[languages]=images\n",
        "            \n",
        "    #After getting all data return the data in Serires and a Dataframe to easily access the data\n",
        "    y=pd.Series(Y)\n",
        "    x=pd.DataFrame.from_dict({(i,j): X[i][j] \n",
        "                               for i in X.keys() \n",
        "                               for j in X[i].keys()},orient='index')\n",
        "    \n",
        "    return x,y,lang_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdTSXhajXuFF",
        "colab_type": "code",
        "outputId": "d40f6cee-24e3-412f-806f-b87bccff999d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#testing module\n",
        "print(\"Getting Trainind data\")\n",
        "x_train,y_train,languages=get_image_data('Fellowship/images_background/')\n",
        "print('Getting Evaluation data')\n",
        "x_val,y_val,languages_val=get_image_data('Fellowship/images_evaluation/')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting Trainind data\n",
            "Getting Evaluation data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdt7CWTYXuFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def siamese_net():\n",
        "    \n",
        "    \"\"\"\n",
        "    Define the architecture of the model which is convolution neraul network with 64 10x10 filters,\n",
        "    relu -> max pool -> convolution with 128 7x7 filters, relu -> max pool -> convolution with 128 4x4 filters,\n",
        "    relu -> max pool -> convolution with 256 4x4 filters.\n",
        "    \"\"\"\n",
        "    \n",
        "    def initialize_weights(shape, dtype=None ,name=None):\n",
        "        \"\"\"\n",
        "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
        "        \"\"\"\n",
        "        return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
        "\n",
        "    def initialize_bias(shape, dtype=None, name=None):\n",
        "        \"\"\"\n",
        "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
        "        \"\"\"\n",
        "        return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)\n",
        "\n",
        "    #Define Imput shape \n",
        "    input_shape=(105,105,3)\n",
        "    left_input=Input(input_shape)\n",
        "    right_input=Input(input_shape)\n",
        "\n",
        "    \"\"\"\n",
        "    Creating a 4 layer model \n",
        "    \"\"\"\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(filters=64,kernel_size=(10,10),activation='relu',\n",
        "                 input_shape=input_shape,kernel_initializer=initialize_weights,kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "\n",
        "    model.add(Conv2D(128,(7,7),activation='relu',kernel_initializer=initialize_weights,\n",
        "                 bias_initializer=initialize_bias,kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "\n",
        "    model.add(Conv2D(128,(4,4),activation='relu',kernel_initializer=initialize_weights,\n",
        "                 bias_initializer=initialize_bias,kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "\n",
        "    model.add(Conv2D(256,(4,4),activation='relu',kernel_initializer=initialize_weights,\n",
        "                 bias_initializer=initialize_bias,kernel_regularizer=l2(2e-4)))\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(4096,activation='sigmoid',kernel_regularizer=l2(1e-3),kernel_initializer=initialize_weights,\n",
        "         bias_initializer=initialize_bias))\n",
        "\n",
        "    encode_l=model(left_input)\n",
        "    encode_r=model(right_input)\n",
        "\n",
        "    l1_layer=Lambda(lambda tensors:K.abs(tensors[0]-tensors[1]))\n",
        "    l1_distance=l1_layer([encode_l,encode_r])\n",
        "\n",
        "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(l1_distance)\n",
        "    \n",
        "    # Connect the inputs with the outputs\n",
        "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "\n",
        "    print(siamese_net.summary())\n",
        "    \n",
        "    return siamese_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-RJVM_RXuFL",
        "colab_type": "code",
        "outputId": "22e4cd39-1074-4c9b-ffd0-ae7c114c43dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "#Create and complie model\n",
        "model=siamese_net()\n",
        "optimizer = Adam(lr = 0.00006)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 105, 105, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           (None, 105, 105, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_5 (Sequential)       (None, 4096)         38960448    input_9[0][0]                    \n",
            "                                                                 input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 4096)         0           sequential_5[1][0]               \n",
            "                                                                 sequential_5[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1)            4097        lambda_5[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 38,964,545\n",
            "Trainable params: 38,964,545\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyTld0fZ8ugr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper parameters\n",
        "evaluate_every =200 # interval for evaluating on one-shot tasks\n",
        "batch_size = 32\n",
        "n_iter = 2000 # No. of training iterations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWDGIV1kXuFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(x):\n",
        "  \"\"\"\n",
        "  Create batch to train the model\n",
        "  \"\"\"\n",
        "  n_classes, n_examples= x.shape\n",
        "  w, h =105,105\n",
        "  categories=np.random.choice(n_classes,size=(batch_size,),replace=False)\n",
        "\n",
        "  # initialize 2 empty arrays for the input image batch\n",
        "  pairs=[np.zeros((batch_size, h, w,3)) for i in range(2)]\n",
        "    \n",
        "  # initialize vector for the targets\n",
        "  targets=np.zeros((batch_size,))\n",
        "\n",
        "  targets[batch_size//2:]=1\n",
        "  for i in range(batch_size):\n",
        "      category=categories[i]\n",
        "      idx_1=np.random.randint(0,n_examples)\n",
        "      pairs[0][i,:,:,:] = x.iat[category, idx_1]\n",
        "      idx_2 = np.random.randint(0, n_examples)\n",
        "      if i >= batch_size // 2:\n",
        "              category_2 = category  \n",
        "      else: \n",
        "          # add a random number to the category modulo n classes to ensure 2nd image has a different category\n",
        "          category_2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
        "      pairs[1][i,:,:,:] = x.iat[category_2,idx_2]\n",
        "    \n",
        "  return pairs,targets\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErZrC8QfXuFZ",
        "colab_type": "code",
        "outputId": "04d209c4-1cdb-4e77-f990-89beb6023433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995
        }
      },
      "source": [
        "print(\"Starting training process!\")\n",
        "l=[]\n",
        "for i in range(1, n_iter+1):\n",
        "    inputs,targets = get_batch(x_train)\n",
        "    loss = model.train_on_batch(inputs,targets)\n",
        "    l.append(loss)\n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"\\n ------------- \\n\")\n",
        "        print(\"Train Loss: {0}\".format(loss))\n",
        "plt.title('Training Loss')\n",
        "plt.plot(l)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training process!\n",
            "\n",
            " ------------- \n",
            "\n",
            "Train Loss: 2.288740873336792\n",
            "\n",
            " ------------- \n",
            "\n",
            "Train Loss: 1.7072113752365112\n",
            "\n",
            " ------------- \n",
            "\n",
            "Train Loss: 1.3755910396575928\n",
            "\n",
            " ------------- \n",
            "\n",
            "Train Loss: 1.1454741954803467\n",
            "\n",
            " ------------- \n",
            "\n",
            "Train Loss: 1.0046484470367432\n",
            "\n",
            " ------------- \n",
            "\n",
            "Train Loss: 0.9348121881484985\n",
            "\n",
            " ------------- \n",
            "\n",
            "Train Loss: 0.909724771976471\n",
            "\n",
            " ------------- \n",
            "\n",
            "Train Loss: 0.699389636516571\n",
            "\n",
            " ------------- \n",
            "\n",
            "Train Loss: 0.7665221691131592\n",
            "\n",
            " ------------- \n",
            "\n",
            "Train Loss: 0.7366732358932495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f33e2f45588>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyHIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou5_tIjMXuFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_test_batch(N):\n",
        "    \"\"\"\n",
        "    Create test batch\n",
        "    \"\"\"\n",
        "    n_classes, n_examples= x_val.shape\n",
        "    w, h =105,105\n",
        "    categories=languages_val\n",
        "\n",
        "\n",
        "    indices=m=np.random.randint(0,n_examples,size=(N,))#choose random images to be selected\n",
        "    categories=np.random.randint(n_classes,size=(N,))\n",
        "    test_image=np.zeros((1,w,h,3))#placehoder for test image\n",
        "\n",
        "    targets=np.zeros((N,))\n",
        "    support_set=[]\n",
        "    targets[0] = 1\n",
        "    true_category = categories[0]\n",
        "    ex1, ex2 = np.random.choice(n_examples,replace=False,size=(2,))\n",
        "    test_image[0] = np.asarray(x_val.iat[true_category,ex1])\n",
        "    for c,i in zip(categories,indices):\n",
        "        support_set.append(x_val.iat[c,i])\n",
        "    support_set[0] = x_val.iat[true_category,ex2]\n",
        "    support_set=np.array(support_set)\n",
        "    targets,support_set = shuffle(targets,support_set)\n",
        "    pairs = [test_image,support_set]\n",
        "    return pairs,targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNL3axTTXuFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testing(k,N):\n",
        "  \"\"\"\n",
        "  Used to test model for k times on N-batch size data\n",
        "  \"\"\"\n",
        "  n_correct=0\n",
        "  for i in range(k):\n",
        "      inputs_t, targets_t = make_test_batch(9)\n",
        "      # ImageLoader(inputs_t)\n",
        "      probs = model.predict_on_batch(inputs_t)\n",
        "      if np.argmax(probs) == np.argmax(targets_t):\n",
        "          n_correct+=1\n",
        "  percent_correct = (100.0 * n_correct / k)\n",
        "  print(\"Got an average of \"+str(percent_correct)+\"% for \"+str(N)+\" way one-shot learning accuracy \\n\")\n",
        "  # return percent_correct\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiPCNzDKkSSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ImageLoader(imlist):\n",
        "  plt.subplots()\n",
        "  plt.title(\"Test Image\")\n",
        "  plt.imshow(imlist[0][0])\n",
        "  print('Subset Images')\n",
        "  new_img=np.zeros((480,480))\n",
        "  offset=2\n",
        "  for img in imlist[1]:\n",
        "      # new_img=+img\n",
        "      # new_image+=offset\n",
        "      plt.subplots()\n",
        "      plt.imshow(img)\n",
        "      # plt.imshow(new_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WHMoPfhznx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "beb73c25-2922-42fa-a7dd-4c32dd5d08cd"
      },
      "source": [
        "N_way=[9,16,25,32]\n",
        "for i in N_way:\n",
        "  testing(32,i)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Got an average of 75.0% for 9 way one-shot learning accuracy \n",
            "\n",
            "Got an average of 71.875% for 16 way one-shot learning accuracy \n",
            "\n",
            "Got an average of 75.0% for 25 way one-shot learning accuracy \n",
            "\n",
            "Got an average of 78.125% for 32 way one-shot learning accuracy \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x7aX6FVXuFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stroke(fp):\n",
        "    with open(fp,'r') as f:\n",
        "        stroke_data=f.readlines()\n",
        "        stroke_data=[l.strip() for l in stroke_data]\n",
        "        motor=[]\n",
        "        for line in stroke_data:\n",
        "            if line==\"START\":\n",
        "                stk=[]\n",
        "            elif line==\"BREAK\":\n",
        "                stk = np.array(stk)\n",
        "                motor.append(stk) # add to list of strokes\n",
        "                stk = [] \n",
        "            else:\n",
        "                arr = np.fromstring(line,dtype=float,sep=',')\n",
        "                stk.append(arr)\n",
        "    return motor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjLuFzPqXuFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_stroke(motor):\n",
        "    drawing=[d[:,0:2]for d in motor]\n",
        "    for i in drawing:\n",
        "        plt.subplots()\n",
        "        plt.plot(i[:,0],i[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdI7A7gOXuFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stroke_data(folder):\n",
        "    \"\"\"\n",
        "    Function to get stroke data and returns a dataframe in accordance to language and character \n",
        "    \"\"\"\n",
        "    lang_list=[]\n",
        "    SX={}\n",
        "    for languages in os.listdir(folder):\n",
        "        if languages.startswith('.'):\n",
        "            continue\n",
        "        else:\n",
        "            strokes={}\n",
        "            lang_list.append(languages)\n",
        "            for alphabets in os.listdir(folder+languages):\n",
        "                if alphabets.startswith('.'):\n",
        "                    continue\n",
        "                else:\n",
        "                    stk=[]\n",
        "                    for character in os.listdir(folder+languages+\"/\"+alphabets):\n",
        "                        if(character.startswith('.')):\n",
        "                            continue\n",
        "                        else:\n",
        "                            stk_data=get_stroke(folder+languages+\"/\"+alphabets+\"/\"+character)\n",
        "                            stk.append(stk_data)\n",
        "                    strokes[alphabets]=stk\n",
        "            \n",
        "        print(languages)\n",
        "        SX[languages]=strokes\n",
        "    \n",
        "    sx=pd.DataFrame.from_dict({(i,j): SX[i][j] \n",
        "                           for i in SX.keys() \n",
        "                           for j in SX[i].keys()},orient='index')\n",
        "    return sx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb58BdckXuFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stroke_train=get_stroke_data('Fellowship/strokes_background/')\n",
        "stroke_test=get_stroke_data('Fellowship/strokes_evaluation/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEYreoK_U-Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzcrN6Xq3pb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/Colab Notebooks/Fellowship\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}